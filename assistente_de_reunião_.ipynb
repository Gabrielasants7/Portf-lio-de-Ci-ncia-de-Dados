{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gabrielasants7/Portfolio-Ciencia-de-Dados/blob/main/assistente_de_reuni%C3%A3o_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWM3-tQh2Kep"
      },
      "source": [
        "# Escopo do Projeto: Assistente de Reuniões com Transcrição e Tradução Automática\n",
        "\n",
        "## Objetivo\n",
        "O objetivo deste projeto é desenvolver um **Assistente de Reuniões** que transcreve em tempo real as discussões durante as reuniões e organiza as informações chave, como **ideias**, **decisões**, **itens de ação** e **prazos**. O assistente não só realiza a transcrição, mas também cria atas de reunião estruturadas e acionáveis, permitindo que os participantes da reunião possam se concentrar na discussão sem se preocupar em perder detalhes importantes.\n",
        "\n",
        "Além disso, o diferencial do projeto será o suporte a **tradução automática** entre **português** e **inglês**, com foco em trabalhadores brasileiros que ainda estão em processo de adaptação à língua inglesa. A ferramenta ajudará na transição e facilitará a compreensão em tempo real, sem barreiras linguísticas.\n",
        "\n",
        "## Funcionalidades\n",
        "1. **Transcrição de Áudio em Tempo Real**:\n",
        "   - O modelo **Whisper** da OpenAI será utilizado para transcrever automaticamente o áudio da reunião para texto em tempo real.\n",
        "   - O áudio será processado e convertido em texto enquanto a reunião ocorre, sem a necessidade de intervenções manuais.\n",
        "\n",
        "2. **Tradução Automática (Português e Inglês)**:\n",
        "   - A transcrição será traduzida automaticamente entre os idiomas **português** e **inglês**, permitindo que os participantes brasileiros possam compreender facilmente as discussões em inglês.\n",
        "   - A tradução será feita com modelos de tradução automática, garantindo que o conteúdo seja acessível para todos os participantes, independentemente da sua fluência em inglês.\n",
        "\n",
        "3. **Organização das Atas de Reunião**:\n",
        "   - O assistente organizará a transcrição em **ata de reunião** estruturada, destacando:\n",
        "     - **Ideias** discutidas.\n",
        "     - **Decisões** tomadas.\n",
        "     - **Itens de ação** com prazos e responsáveis.\n",
        "   - A IA será capaz de identificar automaticamente os pontos mais importantes durante a reunião e gerar um resumo claro e organizado.\n",
        "\n",
        "4. **Interface de Usuário (Gradio)**:\n",
        "   - O sistema permitirá que os usuários façam o **upload de arquivos de áudio** da reunião ou usem a gravação em tempo real.\n",
        "   - A interface será simples, com campos de upload de áudio, exibição da transcrição em tempo real, tradução e as atas geradas.\n",
        "\n",
        "5. **Exportação de Resultados**:\n",
        "   - Os resultados da transcrição e tradução poderão ser exportados em **formato de texto** ou **PDF**, facilitando o compartilhamento com os participantes da reunião.\n",
        "\n",
        "## Tecnologias Utilizadas\n",
        "- **Python 3.x**: Linguagem principal para o desenvolvimento do projeto.\n",
        "- **Transformers (Hugging Face)**: Para utilizar o modelo **Whisper** para transcrição de áudio em tempo real e modelos de tradução automática.\n",
        "- **Torch (PyTorch)**: Framework utilizado para rodar os modelos de aprendizado de máquina.\n",
        "- **Gradio**: Biblioteca para criar uma interface de usuário interativa para upload de áudio e exibição da transcrição e tradução.\n",
        "- **Google Colab**: Ambiente de desenvolvimento utilizado para executar o código, aproveitando recursos de processamento em nuvem.\n",
        "\n",
        "## Fluxo do Sistema\n",
        "1. **Entrada**:\n",
        "   - O usuário faz o upload de um arquivo de áudio de uma reunião ou grava a reunião em tempo real.\n",
        "   \n",
        "2. **Processamento**:\n",
        "   - O arquivo de áudio é enviado para o modelo **Whisper** que realiza a transcrição.\n",
        "   - A transcrição é então traduzida automaticamente entre os idiomas **português** e **inglês**.\n",
        "   \n",
        "3. **Saída**:\n",
        "   - A transcrição e tradução são exibidas em tempo real na interface do Gradio.\n",
        "   - A IA organiza a transcrição em uma **ata de reunião**, destacando decisões, ideias e itens de ação.\n",
        "   \n",
        "4. **Exportação**:\n",
        "   - A ata de reunião pode ser exportada para **PDF** ou **texto**, permitindo o envio para os participantes.\n",
        "\n",
        "\n",
        "## Dependências\n",
        "- **transformers**: Biblioteca para acessar modelos de NLP (Natural Language Processing), como o modelo **Whisper** e modelos de tradução automática.\n",
        "- **torch**: Framework para execução dos modelos de aprendizado profundo.\n",
        "- **gradio**: Biblioteca para criar interfaces de usuário interativas.\n",
        "- **pydantic**: Biblioteca para validar e configurar as entradas e saídas do aplicativo.\n",
        "- **ffmpeg**: Ferramenta para manipulação e conversão de arquivos de áudio, se necessário.\n",
        "\n",
        "## Passos para Execução no Colab\n",
        "1. **Instalar Dependências**:\n",
        "   - Instalar as bibliotecas necessárias com os seguintes comandos:\n",
        "     ```bash\n",
        "    !pip install transformers==4.35.2 pydantic==2.10.3 torch==2.1.1 langchain==0.3.12 langchain-community==0.3.12 gradio==5.9.0 deep_translator googletrans  reportlab\n",
        "     ```\n",
        "   \n",
        "2. **Carregar e Processar o Áudio**:\n",
        "   - Utilizar a função de transcrição do modelo **Whisper**.\n",
        "   - Adicionar a funcionalidade de tradução automática para converter entre português e inglês.\n",
        "   \n",
        "3. **Configurar a Interface Gradio**:\n",
        "   - Criar a interface de upload de áudio e exibir a transcrição e tradução em tempo real.\n",
        "   \n",
        "4. **Testar a Aplicação**:\n",
        "   - Testar a funcionalidade de upload, transcrição e tradução no ambiente Colab.\n",
        "   \n",
        "5. **Gerar Link Público**:\n",
        "   - Usar o parâmetro `share=True` para gerar um link público que permita aos usuários acessarem a aplicação.\n",
        "\n",
        "## Possíveis Melhorias\n",
        "- **Suporte a Outros Idiomas**: Implementar suporte para outros idiomas além do português e inglês, facilitando a inclusão de participantes de diferentes regiões.\n",
        "\n",
        "- **Integração com Calendários**: Integrar o sistema com ferramentas de calendário (como Google Calendar) para automaticamente gerar atas com base nas reuniões agendadas.\n",
        "\n",
        "## Dado para teste\n",
        "\n",
        "- **faça o upload do dado para teste  aqui\n",
        "\n",
        "https://drive.google.com/file/d/1TBPIRdfdVKlqAx_SFdHuSF-Qh-duek-x/view?usp=sharing\n",
        "\n",
        "\n",
        "\n",
        "## Conclusão\n",
        "Este projeto visa simplificar o processo de **anotação de reuniões** e **organização de tarefas**, ao mesmo tempo em que facilita a comunicação entre equipes internacionais, com suporte a **tradução em tempo real** e **transcrição automática**.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjvJuxg03JkT",
        "outputId": "51de516f-f843-4b4a-d63d-6fa60fcd9178"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.35.2 in /usr/local/lib/python3.11/dist-packages (4.35.2)\n",
            "Requirement already satisfied: pydantic==2.10.3 in /usr/local/lib/python3.11/dist-packages (2.10.3)\n",
            "Requirement already satisfied: torch==2.1.1 in /usr/local/lib/python3.11/dist-packages (2.1.1)\n",
            "Requirement already satisfied: langchain==0.3.12 in /usr/local/lib/python3.11/dist-packages (0.3.12)\n",
            "Requirement already satisfied: langchain-community==0.3.12 in /usr/local/lib/python3.11/dist-packages (0.3.12)\n",
            "Requirement already satisfied: gradio==5.9.0 in /usr/local/lib/python3.11/dist-packages (5.9.0)\n",
            "Requirement already satisfied: deep_translator in /usr/local/lib/python3.11/dist-packages (1.11.4)\n",
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.11/dist-packages (4.0.2)\n",
            "Collecting reportlab\n",
            "  Downloading reportlab-4.2.5-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.2) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.2) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.2) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.2) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.2) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.2) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.2) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.10.3) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.10.3) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.10.3) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.1) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.1.1) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.1) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.1) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.1) (2.1.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.12) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.12) (3.11.11)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.12) (0.3.32)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.12) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.12) (0.2.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.12) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.12) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.12) (0.4.0)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.12) (2.7.1)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.9.0) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.9.0) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio==5.9.0) (0.115.8)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio==5.9.0) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.5.2 in /usr/local/lib/python3.11/dist-packages (from gradio==5.9.0) (1.5.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio==5.9.0) (0.28.1)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.9.0) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.9.0) (3.10.15)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.9.0) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.9.0) (11.1.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio==5.9.0) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio==5.9.0) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from gradio==5.9.0) (0.9.4)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio==5.9.0) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.9.0) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.9.0) (0.45.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.9.0) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio==5.9.0) (0.15.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.9.0) (0.34.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.5.2->gradio==5.9.0) (14.2)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.1) (12.5.82)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.11/dist-packages (from deep_translator) (4.12.3)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from reportlab) (5.2.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.12) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.12) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.12) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.12) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.12) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.12) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.12) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio==5.9.0) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio==5.9.0) (1.3.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.6)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.12) (3.26.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.12) (0.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==5.9.0) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==5.9.0) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio==5.9.0) (0.14.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.27.2->googletrans) (4.2.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain==0.3.12) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.12) (1.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==5.9.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==5.9.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==5.9.0) (2025.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.12) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.35.2) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.35.2) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.12) (3.1.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==5.9.0) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==5.9.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==5.9.0) (13.9.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.1) (1.3.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans) (4.1.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.25->langchain==0.3.12) (3.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio==5.9.0) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==5.9.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==5.9.0) (2.18.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.12) (1.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio==5.9.0) (0.1.2)\n",
            "Downloading reportlab-4.2.5-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: reportlab\n",
            "Successfully installed reportlab-4.2.5\n"
          ]
        }
      ],
      "source": [
        "#instalando as bibliotecas necessárias\n",
        "!pip install transformers==4.35.2 pydantic==2.10.3 torch==2.1.1 langchain==0.3.12 langchain-community==0.3.12 gradio==5.9.0 deep_translator googletrans  reportlab\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knn_z9wm4YFs",
        "outputId": "e729630e-30b2-417d-e620-04ed076b5cca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "#instalando a biblioteca para pré-processamento e manipulação de  arquivos de áudio\n",
        "!apt install ffmpeg -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "q8RahCat7ROB",
        "outputId": "b9bdbc13-9335-4e0a-8536-e36f89dbc1ac"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-07b67dd7-1130-4086-9797-fa6b1ee609a1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-07b67dd7-1130-4086-9797-fa6b1ee609a1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving trimmed_02.wav to trimmed_02 (1).wav\n"
          ]
        }
      ],
      "source": [
        "#fazendo upload do arquivo\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "IRAvsRgnAbvu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca2583f0-b815-4a2d-fcad-54a1701575f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Transcrição em Inglês:\n",
            "  99% confidence level indicating that our maximum loss will mat exceed 5 million in the next trading day. We've adopted a conservative approach to managing our leverage and have a healthy tier one capital ratio of 12.5%. Our forecast for the coming quarter is positive. We expect revenue to be around 135 million and 8% quarter over quarter growth driven primarily by our cutting-edge blockchain chain solutions and AI driven predictive analytics. We're also excited about the upcoming IPO of our FinTech subsidiary pay plus which we expect to raise 200 million significantly bolstering our liquidity and paving the way for aggressive growth strategies. We thank our shareholders for their continued faith in us and we look forward to an even more successful Q3. Thank you so much.\n",
            "\n",
            "🔹 Tradução para Português:\n",
            " Nível de confiança de 99% indicando que nossa perda máxima pode exceder 5 milhões no próximo dia de negociação. Adotamos uma abordagem conservadora para gerenciar nossa alavancagem e temos um índice de capital de nível um saudável de 12,5%. Nossa previsão para o próximo trimestre é positiva. Esperamos que a receita fique em torno de 135 milhões e 8% de crescimento trimestre a trimestre impulsionado principalmente por nossas soluções de cadeia de blockchain de ponta e análise preditiva orientada por IA. Também estamos animados com o próximo IPO de nossa subsidiária FinTech pay plus, que esperamos arrecadar 200 milhões, reforçando significativamente nossa liquidez e abrindo caminho para estratégias de crescimento agressivas. Agradecemos aos nossos acionistas por sua fé contínua em nós e esperamos um terceiro trimestre ainda mais bem-sucedido. Muito obrigado.\n"
          ]
        }
      ],
      "source": [
        "#importação das bibliotecas\n",
        "import torch #transcrição para processar os dados\n",
        "from transformers import pipeline # fornece o modelo Whisper que faz a transcrição de áudio em texto\n",
        "from deep_translator import GoogleTranslator # tradução\n",
        "import os #gerenciar diretórios e arquivos do sistema\n",
        "import gradio as gr #cria a interface web para upload de áudio e interação com o usuário\n",
        "from reportlab.lib.pagesizes import A4 #Gera o PDF formatado da ata da reunião\n",
        "from reportlab.pdfgen import canvas\n",
        "from reportlab.lib.utils import simpleSplit\n",
        "from datetime import datetime #obtém a data atual para organizar os arquivos da reunião.\n",
        "\n",
        "#  pipeline de reconhecimento de fala (ASR)\n",
        "pipe = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=\"openai/whisper-tiny.en\",\n",
        "    chunk_length_s=30,\n",
        ")\n",
        "\n",
        "#  arquivo de áudio\n",
        "sample = \"trimmed_02.wav\"\n",
        "\n",
        "# rodando a transcrição\n",
        "transcription_en = pipe(sample, batch_size=8)[\"text\"]\n",
        "\n",
        "# traduzindo para português\n",
        "translator = GoogleTranslator(source=\"en\", target=\"pt\")\n",
        "transcription_pt = translator.translate(transcription_en)\n",
        "\n",
        "# exibindo os resultados\n",
        "print(\"🔹 Transcrição em Inglês:\\n\", transcription_en)\n",
        "print(\"\\n🔹 Tradução para Português:\\n\", transcription_pt)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# criando o pipeline de transcrição\n",
        "pipe = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=\"openai/whisper-tiny.en\",\n",
        "    chunk_length_s=30,\n",
        ")\n",
        "\n",
        "# função para transcrever e traduzir áudio\n",
        "def transcript_audio(audio_file):\n",
        "    # criando diretório para armazenar os arquivos\n",
        "    data_atual = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    folder_name = f\"Atas_de_Reunioes/{data_atual}_Reuniao\"\n",
        "    os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "    # processando transcrição\n",
        "    result = pipe(audio_file)[\"text\"]\n",
        "    translation = GoogleTranslator(source=\"auto\", target=\"pt\").translate(result)\n",
        "\n",
        "    # salvando gravação no diretório\n",
        "    audio_path = os.path.join(folder_name, os.path.basename(audio_file))\n",
        "    os.rename(audio_file, audio_path)\n",
        "\n",
        "    # criando e salvando PDF formatado\n",
        "    pdf_path = generate_meeting_pdf(data_atual, translation, audio_path)\n",
        "\n",
        "    return (\n",
        "        f\"**Transcrição (Inglês):**\\n{result}\\n\\n**Transcrição (Português):**\\n{translation}\",\n",
        "        pdf_path,\n",
        "    )\n",
        "\n",
        "# função para gerar PDF formatado corretamente\n",
        "def generate_meeting_pdf(date, transcription, audio_path):\n",
        "    pdf_path = f\"Atas_de_Reunioes/{date}_Reuniao/{date}_Ata.pdf\"\n",
        "    c = canvas.Canvas(pdf_path, pagesize=A4)\n",
        "    width, height = A4\n",
        "\n",
        "    # cabeçalho\n",
        "    c.setFont(\"Helvetica-Bold\", 14)\n",
        "    c.drawString(50, height - 50, f\"📅 Data: {date}\")\n",
        "\n",
        "    # linha de separação\n",
        "    c.setStrokeColorRGB(0, 0, 0)\n",
        "    c.line(50, height - 60, width - 50, height - 60)\n",
        "\n",
        "    # adicionando a transcrição ao PDF\n",
        "    c.setFont(\"Helvetica-Bold\", 12)\n",
        "    c.drawString(50, height - 80, \"📝 Transcrição (Português):\")\n",
        "    c.setFont(\"Helvetica\", 12)\n",
        "\n",
        "    # dividindo o texto para evitar cortes\n",
        "    text_lines = simpleSplit(transcription, \"Helvetica\", 12, width - 100)\n",
        "    y_position = height - 110\n",
        "\n",
        "    for line in text_lines:\n",
        "        if y_position < 50:  # criar nova página se o texto ultrapassar o limite\n",
        "            c.showPage()\n",
        "            y_position = height - 50\n",
        "            c.setFont(\"Helvetica\", 12)\n",
        "        c.drawString(50, y_position, line)\n",
        "        y_position -= 20\n",
        "\n",
        "    # adicionando link da gravação\n",
        "    c.setFont(\"Helvetica-Bold\", 12)\n",
        "    c.drawString(50, y_position - 20, f\"🔗 Link para a Gravação: {audio_path}\")\n",
        "\n",
        "    # salvando PDF\n",
        "    c.save()\n",
        "    return pdf_path\n",
        "\n",
        "# função para pesquisa por palavras-chave\n",
        "def search_keywords(transcription, keyword):\n",
        "    if keyword.lower() in transcription.lower():\n",
        "        return f\"🔎 Palavra-chave encontrada: **{keyword}** aparece na transcrição!\"\n",
        "    return \"❌ Palavra-chave não encontrada.\"\n",
        "\n",
        "# interface Gradio\n",
        "audio_input = gr.Audio(sources=\"upload\", type=\"filepath\")\n",
        "output_text = gr.Textbox(label=\"Transcrição e Tradução\")\n",
        "keyword_input = gr.Textbox(label=\"🔍 Pesquisar Palavra-Chave\")\n",
        "keyword_output = gr.Textbox(label=\"Resultado da Pesquisa\")\n",
        "download_pdf = gr.File(label=\"📄 Baixar PDF\")\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=transcript_audio,\n",
        "    inputs=audio_input,\n",
        "    outputs=[output_text, download_pdf],\n",
        "    title=\"📌 Assistente de Reuniões com IA\",\n",
        "    description=\"📢 Faça o upload do áudio da reunião para transcrição e tradução automática. Gere atas formatadas e pesquise palavras-chave na transcrição.\",\n",
        ")\n",
        "\n",
        "iface.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "KNWbNhOg7AM3",
        "outputId": "3af557e8-fd3f-4638-827c-9ea63d02bac6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6616649ce3c8031c57.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6616649ce3c8031c57.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWatdmuYf0JKJf6Z04dfui",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}